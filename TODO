# TODO

## 1. Infrastructure Setup ✅

- [x] **Pulumi Project Initialization**
  - [x] Initialize a new Pulumi project (Python)
  - [x] Install the Pulumi AWS provider
  - [x] Configure Pulumi to deploy resources in the correct AWS region

- [x] **Create AWS Resources via Pulumi**
  - [x] **S3 Bucket**  
    - [x] Create an S3 bucket for logs, checkpoints, artifacts
    - [x] Configure bucket policies / encryption / versioning
    - [x] Add lifecycle rules to move old data to cheaper storage
  - [x] **IAM Role**  
    - [x] Create an IAM role for EC2, granting read/write to the S3 bucket
    - [x] Attach role to instance profile
  - [x] **EC2 Launch Template**  
    - [x] Base AMI (using AWS Deep Learning AMI)
    - [x] User data script to install dependencies
    - [x] Configure EC2 key pairs for secure SSH access
  - [x] **Auto Scaling Group**  
    - [x] Configure mixed instances policy with GPU instance types
    - [x] Set up Spot instances with capacity-optimized allocation
    - [x] Configure desired capacity
  - [x] **Security Group**  
    - [x] Open required ports
    - [x] Attach to ASG/instances
  - [x] **Output**  
    - [x] Print relevant infrastructure info

## 2. Wrapper Class Implementation ✅

- [x] **Core Class Structure**
  - [x] Create `ReceiptTrainer` class
  - [x] Initialize with configuration parameters
  - [x] Set up logging and environment validation
  - [x] Implement device selection logic

- [x] **Data Management**
  - [x] **Dataset Loading**
    - [x] Integrate DynamoDB data loading
    - [x] Add SROIE dataset integration
    - [x] Create unified data loading pipeline
  - [x] **Data Validation**
    - [x] Add input validation for DynamoDB data
    - [x] Validate combined dataset structure
    - [x] Add dataset statistics reporting
  - [x] **Data Processing**
    - [x] Implement data balancing logic
    - [x] Implement sliding window functionality
    - [x] Add data augmentation methods

- [x] **Model Management**
  - [x] **Model Configuration**
    - [x] Encapsulate LayoutLM model setup
    - [x] Add model checkpoint handling
    - [x] Implement model versioning
  - [x] **Training Pipeline**
    - [x] Basic training loop implementation
    - [x] Add early stopping
    - [x] Implement gradient accumulation
    - [x] Add mixed precision training
  - [x] **Evaluation**
    - [x] Add metrics computation
    - [x] Implement validation loop
    - [x] Add performance reporting

- [x] **W&B Integration**
  - [x] **Project Setup**
    - [x] Initialize W&B project
    - [x] Configure artifact storage
    - [x] Set up experiment tracking
  - [x] **Logging**
    - [x] Add metric logging
    - [x] Log model checkpoints
    - [x] Track dataset versions

- [x] **AWS Integration**
  - [x] **S3 Management**
    - [x] Add checkpoint saving/loading
    - [x] Implement artifact storage
    - [x] Handle dataset caching
  - [x] **Spot Instance Handling**
    - [x] Add spot interruption handlers
    - [x] Implement training resumption
    - [x] Add auto-scaling management

- [x] **Testing**
  - [x] Add unit tests for core functionality
  - [x] Create integration tests
  - [x] Add test fixtures and mocks
  - [x] Test error handling

## 3. Receipt Trainer Package ✅

- [x] **Package Structure**
  - [x] Organize code into a proper Python package structure
  - [x] Create a clean package layout with modules and subpackages
  - [x] Add package configuration files (pyproject.toml, requirements.txt)
  - [x] Implement version management

- [x] **Core Components**
  - [x] Implement the main trainer module for model training
  - [x] Create configuration management
  - [x] Develop utility functions and helpers
  - [x] Define constants and shared resources

- [ ] **Package Improvements**
  - [ ] Add more examples in the examples directory
  - [ ] Improve test coverage for all modules
  - [ ] Create comprehensive API documentation
  - [ ] Add installation and setup guides
  - [ ] Implement CI/CD pipeline for the package
  - [ ] Publish package to PyPI for easier installation

## 4. Additional Features

- [x] **Hyperparameter Optimization**
  - [x] Set up W&B sweeps configuration
  - [x] Implement distributed training support
    - [x] Added distributed training configuration parameters
    - [x] Modified training loop for multi-GPU training
    - [x] Implemented proper data loading for distributed processes
    - [x] Added process synchronization and cleanup
    - [x] Created example script for distributed training
  - [x] Add early stopping for sweeps
  - [x] Add automated hyperparameter reporting
  - [x] Implement parallel sweep execution

- [x] **Performance Optimization**
  - [x] Implement gradient accumulation
  - [x] Add mixed precision training
  - [x] Optimize data loading pipeline
  - [x] Add model validation checks
  - [x] Implement checkpoint optimization

- [ ] **Documentation**
  - [x] Add docstrings and type hints
  - [x] Create README with usage examples
  - [x] Add API documentation
  - [x] Create training guide
  - [ ] Add architecture diagrams
  - [ ] Document performance benchmarks
  - [ ] Create troubleshooting guide

- [ ] **Error Handling & Monitoring**
  - [x] Add comprehensive error messages
  - [ ] Implement training monitoring
  - [ ] Add system resource monitoring
  - [ ] Implement automatic error recovery
  - [ ] Add error reporting dashboard
  - [ ] Create alert system for training issues

## 5. Future Enhancements

- [ ] **Model Improvements**
  - [ ] Experiment with different LayoutLM variants
  - [ ] Add support for custom model architectures
  - [ ] Implement model ensembling
  - [ ] Add model pruning capabilities
  - [ ] Support for model quantization
  - [ ] Add model interpretability tools

- [ ] **Data Pipeline Enhancements**
  - [ ] Add support for additional datasets
  - [ ] Implement online data augmentation
  - [ ] Add data quality metrics
  - [ ] Create data versioning system
  - [ ] Add support for custom data formats
  - [ ] Implement data cleaning pipeline

- [ ] **Deployment**
  - [ ] Create model serving pipeline
  - [ ] Add model compression for inference
  - [ ] Implement A/B testing framework
  - [ ] Add monitoring for deployed models
  - [ ] Create deployment automation tools
  - [ ] Add rollback capabilities

- [x] **CI/CD**
  - [x] Set up GitHub Actions for automated deployment
  - [x] Configure stack-specific resources and environments (dev/prod)
  - [x] Implement secure key pair management for EC2 instances
  - [x] Add code quality checks (Black, Flake8)
  - [x] Optimize CI/CD workflow with caching
  - [x] Improve test coverage configuration
  - [ ] Create release automation
  - [ ] Implement security scanning

- [ ] **Observability**
  - [ ] Add detailed logging system
  - [ ] Create performance dashboards
  - [ ] Implement metrics collection
  - [ ] Add tracing capabilities
  - [ ] Create alerting system
  - [ ] Add debugging tools 

## 6. ASG-based Training Orchestration

- [x] **Infrastructure Enhancement**
  - [x] Add CloudWatch event handlers for spot interruption
  - [x] Create EFS storage for shared data across instances
  - [x] Set up proper IAM permissions for cross-instance communication
  - [x] Implement auto-registration of new instances
  - [x] Configure stack-specific key pairs for secure SSH access

- [ ] **Job Queue System**
  - [ ] Create SQS queue for training job management
  - [ ] Implement job serialization/deserialization
  - [ ] Add priority scheduling for critical jobs
  - [ ] Build retry mechanism with backoff

- [ ] **Training Job Management**
  - [ ] Create job definition format (YAML/JSON)
  - [ ] Implement job status tracking in DynamoDB
  - [ ] Build CLI tool for job submission/monitoring
  - [ ] Add support for dependency chains between jobs

- [ ] **Instance Coordination**
  - [ ] Implement leader election for multi-instance coordination
  - [ ] Create shared state management system
  - [ ] Add heartbeat mechanism for instance health monitoring
  - [ ] Implement graceful handover on spot termination

- [ ] **Launch Automation**
  - [ ] Create standardized EC2 user-data script
  - [ ] Set up auto-pull from GitHub/CodeCommit on instance launch
  - [ ] Implement environment configuration from parameters store
  - [ ] Build instance bootstrapping with conda/pip dependencies
  - [ ] Add startup health checks and reporting
  - [ ] Create self-diagnostics for GPU availability and performance

- [ ] **Containerization**
  - [ ] Create Docker image with all dependencies pre-installed
  - [ ] Set up GPU support in container with NVIDIA Container Toolkit
  - [ ] Implement volume mounting for checkpoints and data
  - [ ] Build container registry integration (ECR)
  - [ ] Create versioning system for container images
  - [ ] Add container health monitoring

- [ ] **Experiment Tracking**
  - [ ] Extend W&B integration for distributed experiments
  - [ ] Create central dashboard for all training runs
  - [ ] Add resource utilization tracking per experiment
  - [ ] Implement cross-experiment comparison tools

- [ ] **Cost Optimization**
  - [ ] Set up budget alerts and guardrails
  - [ ] Implement instance type selection based on workload
  - [ ] Add automatic shutdown of idle instances
  - [ ] Create cost attribution per experiment/team
  - [ ] Build reporting tools for cost analysis 

## 7. Package Maintenance and Improvements ✅

- [x] **Package Structure Refactoring**
  - [x] Migrate code to 'receipt_dynamo' package
  - [x] Publish package to PyPI
  - [x] Fix circular import issues
  - [x] Optimize import structure
  - [x] Update handler code to match new package structure

- [x] **Testing Infrastructure**
  - [x] Fix test discovery in IDE
  - [x] Update test imports to match new package structure
  - [x] Configure proper coverage reporting
  - [x] Improve test environment setup
  - [x] Add development mode installation for testing 