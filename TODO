# TODO

## 1. Infrastructure Setup

- [x] **Pulumi Project Initialization**
  - [x] Initialize a new Pulumi project (Python)
  - [x] Install the Pulumi AWS provider
  - [x] Configure Pulumi to deploy resources in the correct AWS region

- [x] **Create AWS Resources via Pulumi**
  - [x] **S3 Bucket**  
    - [x] Create an S3 bucket for logs, checkpoints, artifacts
    - [x] Configure bucket policies / encryption / versioning (enabled AES256 encryption and versioning)
    - [x] Add lifecycle rules to move old data to cheaper storage (30 days -> STANDARD_IA, 90 days -> GLACIER)
  - [x] **IAM Role**  
    - [x] Create an IAM role for EC2, granting read/write to the S3 bucket
    - [x] Attach role to instance profile
  - [x] **EC2 Launch Template**  
    - [x] Base AMI (using AWS Deep Learning AMI)
    - [x] User data script to install dependencies and set up environment
  - [x] **Auto Scaling Group**  
    - [x] Configure mixed instances policy with multiple GPU instance types (p3.2xlarge, p3.8xlarge, g4dn.xlarge)
    - [x] Set the purchasing option to Spot
    - [x] Use capacity-optimized allocation strategy
    - [x] Set desired capacity (0 by default, configurable)
  - [x] **Security Group**  
    - [x] Open required ports (SSH port 22)
    - [x] Attach the security group to the ASG/instances
  - [x] **Output**  
    - [x] Print relevant info (ASG name, S3 bucket name, security group ID)

- [x] **Pulumi Deployment**
  - [x] Run `pulumi up` to create all infrastructure
  - [x] Verify resources are created successfully on AWS

## 2. Configure W&B Sweeps

- [ ] **W&B Project Setup**
  - [ ] Create or select a W&B project for hyperparameter sweeps
  - [ ] (Optional) Enable "Bring Your Own Bucket" (BYOB) in W&B if you want artifacts stored in your new S3 bucket

- [ ] **Sweep Configuration**
  - [ ] Define sweep config (hyperparameter search space, optimization metric, search method, etc.)
  - [ ] Save config in a YAML or JSON file (e.g., `sweep.yaml`)
  - [ ] Run `wandb sweep sweep.yaml` to create a sweep and retrieve the sweep ID

## 3. Training Script Updates

- [ ] **Checkpointing**
  - [ ] Add periodic `torch.save()` calls to save model/optimizer states to S3
  - [ ] (Optional) Use 2-minute spot interruption notice to trigger final checkpoint save
  
- [ ] **W&B Integration**
  - [ ] Use `wandb.init()` in the training script
  - [ ] Log metrics, artifacts, etc. to W&B
  - [ ] (Optional) Implement run resume logic with `wandb.run.resume()` if needed

## 4. Testing & Validation

- [ ] **Spot Interruption Simulation**
  - [ ] Force-stop or terminate an instance mid-training
  - [ ] Confirm you can resume from checkpoint on a new instance
  - [ ] Verify logs and metrics are available in W&B

- [ ] **Monitor Costs & Interruptions**
  - [ ] Check AWS Spot Instance dashboard for frequency of interruptions
  - [ ] Verify you are getting the expected savings vs. on-demand

- [ ] **Sweep Execution**
  - [ ] Launch multiple parallel runs by setting the ASG desired capacity or using `wandb agent <sweep-id>`
  - [ ] Confirm W&B is tracking all runs properly (metrics, logs, artifacts)
  - [ ] Adjust hyperparameter search strategy if needed (e.g., reduce search space, early stopping, etc.)

## 5. Cleanup & Optimization

- [ ] **Resource Teardown**
  - [ ] After sweeps complete, either:
    - [ ] Scale ASG desired capacity to 0 or
    - [ ] `pulumi destroy` the entire stack
  - [ ] Retain or archive S3 logs and checkpoints for reference

- [ ] **Further Optimization**
  - [ ] Use Bayesian search or other advanced search methods to reduce trials
  - [ ] Tune checkpoint intervals if you see too much overhead or risk of losing data
  - [ ] Try different instance types or regions to find lower interruption rates and costs
  - [ ] Consider partial on-demand usage if final training run needs guaranteed uninterrupted compute

## 6. Wrapper Class Implementation

- [x] **Core Class Structure**
  - [x] Create `ReceiptTrainer` class
  - [x] Initialize with configuration parameters:
    - [x] W&B project settings
    - [x] Model configuration (LayoutLM parameters)
    - [x] Training hyperparameters
    - [x] AWS/DynamoDB configuration
    - [x] Data processing settings

- [ ] **Data Management**
  - [ ] **Dataset Loading**
    - [ ] Integrate DynamoDB data loading from `dev.make_dataset.py`
    - [ ] Add SROIE dataset integration from `dev.prepare_sroie.py`
    - [ ] Create unified data loading pipeline
  - [ ] **Data Processing**
    - [ ] Port balancing logic from `balance_dataset()`
    - [ ] Implement sliding window functionality from `create_sliding_windows()`
    - [ ] Add data augmentation methods
  - [ ] **Data Validation**
    - [ ] Add input validation for DynamoDB data
    - [ ] Validate combined dataset structure
    - [ ] Add dataset statistics reporting

- [ ] **Model Management**
  - [ ] **Model Configuration**
    - [ ] Encapsulate LayoutLM model setup
    - [ ] Add model checkpoint handling
    - [ ] Implement model versioning
  - [ ] **Training Pipeline**
    - [ ] Port training logic from `dev.training.py`
    - [ ] Add early stopping and model selection
    - [ ] Implement gradient accumulation and mixed precision
  - [ ] **Evaluation**
    - [ ] Add metrics computation
    - [ ] Implement validation loop
    - [ ] Add performance reporting

- [ ] **W&B Integration**
  - [ ] **Project Setup**
    - [ ] Initialize W&B project
    - [ ] Configure artifact storage with S3 bucket
    - [ ] Set up experiment tracking
  - [ ] **Logging**
    - [ ] Add metric logging
    - [ ] Log model checkpoints
    - [ ] Track dataset versions
  - [ ] **Sweep Management**
    - [ ] Implement sweep configuration
    - [ ] Add hyperparameter optimization
    - [ ] Handle distributed training

- [ ] **AWS Integration**
  - [ ] **S3 Management**
    - [ ] Add checkpoint saving/loading
    - [ ] Implement artifact storage
    - [ ] Handle dataset caching
  - [ ] **Spot Instance Handling**
    - [ ] Add spot interruption handlers
    - [ ] Implement training resumption
    - [ ] Add auto-scaling management

- [ ] **Utility Functions**
  - [ ] Add logging and error handling
  - [ ] Create progress tracking
  - [ ] Implement performance profiling
  - [ ] Add debugging tools

- [ ] **Documentation**
  - [ ] Write class and method documentation
  - [ ] Add usage examples
  - [ ] Create training pipeline guide
  - [ ] Document configuration options

- [ ] **Testing**
  - [ ] Add unit tests for core functionality
  - [ ] Create integration tests
  - [ ] Add performance benchmarks
  - [ ] Test spot instance recovery

Example Usage (Draft):
```python
from receipt_trainer import ReceiptTrainer

# Initialize trainer
trainer = ReceiptTrainer(
    wandb_project="receipt-training",
    model_name="microsoft/layoutlm-base-uncased",
    dynamo_table="prod-receipts",
    s3_bucket="training-artifacts"
)

# Load and prepare data
trainer.load_data(
    use_sroie=True,
    balance_ratio=0.7,
    augment=True
)

# Configure training
trainer.configure_training(
    batch_size=16,
    learning_rate=3e-4,
    num_epochs=20,
    gradient_accumulation_steps=32
)

# Start training
trainer.train(
    enable_checkpointing=True,
    enable_early_stopping=True,
    log_to_wandb=True
)

# Export model
trainer.save_model("./trained_model")
```