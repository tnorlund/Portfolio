name: CI Performance Monitoring

on:
  workflow_run:
    workflows: ["Main CI/CD Pipeline", "PR Checks"]
    types: [completed]
  schedule:
    # Run daily at 3 AM UTC to analyze CI performance
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      days:
        description: 'Days to analyze (default: 7)'
        required: false
        default: '7'
      generate_report:
        description: 'Generate detailed report'
        type: boolean
        default: true

jobs:
  collect-metrics:
    name: Collect CI Metrics
    runs-on: ubuntu-latest
    if: github.event.workflow_run.conclusion == 'success' || github.event.workflow_run.conclusion == 'failure' || github.event_name == 'workflow_dispatch'
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests python-dateutil psutil
      
      - name: Collect workflow metrics
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python scripts/ci_profiler.py --collect --job-name "ci-performance-monitor"
      
      - name: Upload metrics
        uses: actions/upload-artifact@v4
        with:
          name: ci-metrics-${{ github.run_id }}
          path: ci-metrics/
          retention-days: 30

  analyze-performance:
    name: Analyze CI Performance
    runs-on: ubuntu-latest
    needs: collect-metrics
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests python-dateutil psutil matplotlib seaborn pandas
      
      - name: Download historical metrics
        uses: actions/download-artifact@v4
        with:
          pattern: ci-metrics-*
          path: ci-metrics/
          merge-multiple: true
      
      - name: Analyze CI performance
        run: |
          python scripts/ci_profiler.py --analyze --days ${{ github.event.inputs.days || '7' }} --format json > ci_analysis.json
      
      - name: Generate performance report
        if: github.event.inputs.generate_report == 'true' || github.event_name == 'schedule'
        run: |
          python scripts/ci_profiler.py --report --format text > ci_performance_report.md
      
      - name: Create performance dashboard
        run: |
          python scripts/create_performance_dashboard.py ci_analysis.json
      
      - name: Upload analysis results
        uses: actions/upload-artifact@v4
        with:
          name: ci-performance-analysis-${{ github.run_id }}
          path: |
            ci_analysis.json
            ci_performance_report.md
            performance_dashboard.html
          retention-days: 90
      
      - name: Comment on PR if triggered by workflow_run
        if: github.event.workflow_run.event == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Read the analysis results
            let analysis = {};
            try {
              analysis = JSON.parse(fs.readFileSync('ci_analysis.json', 'utf8'));
            } catch (e) {
              console.log('Could not read analysis file');
              return;
            }
            
            // Get PR number from the triggering workflow
            const prNumber = context.payload.workflow_run.pull_requests[0]?.number;
            if (!prNumber) {
              console.log('No PR number found');
              return;
            }
            
            // Generate performance summary
            const summary = analysis.summary || {};
            const jobs = analysis.jobs || {};
            
            let comment = `## ðŸ“Š CI Performance Summary\n\n`;
            comment += `**Analysis Period:** Last 7 days\n`;
            comment += `**Total Runs:** ${summary.total_runs || 0}\n\n`;
            
            // Add job performance details
            if (Object.keys(jobs).length > 0) {
              comment += `### Job Performance\n\n`;
              comment += `| Job | Avg Duration | Success Rate | Bottlenecks |\n`;
              comment += `|-----|--------------|--------------|-------------|\n`;
              
              for (const [jobName, jobData] of Object.entries(jobs)) {
                const avgDuration = jobData.duration_stats?.avg || 0;
                const successRate = (jobData.success_rate || 0) * 100;
                const bottlenecks = jobData.bottlenecks?.length || 0;
                
                comment += `| ${jobName} | ${avgDuration.toFixed(1)}s | ${successRate.toFixed(1)}% | ${bottlenecks} |\n`;
              }
            }
            
            comment += `\n*Generated by CI Performance Monitor*`;
            
            // Post comment
            await github.rest.issues.createComment({
              issue_number: prNumber,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  optimize-recommendations:
    name: Generate Optimization Recommendations
    runs-on: ubuntu-latest
    needs: analyze-performance
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      
      - name: Download analysis results
        uses: actions/download-artifact@v4
        with:
          name: ci-performance-analysis-${{ github.run_id }}
      
      - name: Generate optimization recommendations
        run: |
          python scripts/generate_ci_recommendations.py ci_analysis.json > optimization_recommendations.md
      
      - name: Create optimization issue
        if: github.event_name == 'schedule'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Read recommendations
            let recommendations = '';
            try {
              recommendations = fs.readFileSync('optimization_recommendations.md', 'utf8');
            } catch (e) {
              console.log('Could not read recommendations file');
              return;
            }
            
            // Check if there are actionable recommendations
            if (recommendations.includes('No optimization recommendations')) {
              console.log('No optimization recommendations to report');
              return;
            }
            
            const title = `CI Performance Optimization Recommendations - ${new Date().toISOString().split('T')[0]}`;
            
            // Check if a similar issue already exists
            const { data: issues } = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: 'ci-optimization',
              state: 'open'
            });
            
            if (issues.length > 0) {
              console.log('CI optimization issue already exists');
              return;
            }
            
            // Create new issue with recommendations
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: recommendations,
              labels: ['ci-optimization', 'performance']
            });
      
      - name: Upload recommendations
        uses: actions/upload-artifact@v4
        with:
          name: ci-optimization-recommendations-${{ github.run_id }}
          path: optimization_recommendations.md
          retention-days: 30

  cache-analysis:
    name: Analyze Cache Performance
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup cache analysis environment
        run: |
          sudo apt-get update
          sudo apt-get install -y jq
      
      - name: Download cache metrics
        uses: actions/cache@v3
        with:
          path: .ci-cache
          key: ci-performance-cache-${{ github.run_id }}
          restore-keys: |
            ci-performance-cache-
      
      - name: Analyze cache effectiveness
        run: |
          ./scripts/optimize_ci_cache.sh --analyze
      
      - name: Generate cache recommendations
        run: |
          echo "# Cache Performance Analysis" > cache_analysis.md
          echo "" >> cache_analysis.md
          echo "Generated: $(date)" >> cache_analysis.md
          echo "" >> cache_analysis.md
          
          if [[ -f .ci-cache/analysis/cache_analysis_*.json ]]; then
            latest_analysis=$(ls -t .ci-cache/analysis/cache_analysis_*.json | head -n1)
            
            echo "## Cache Hit Rate" >> cache_analysis.md
            jq -r '.cache_performance.hit_rate_percent' "$latest_analysis" | \
              xargs -I {} echo "**{}%** cache hit rate" >> cache_analysis.md
            echo "" >> cache_analysis.md
            
            echo "## Cache Size" >> cache_analysis.md
            jq -r '.cache_performance.cache_size' "$latest_analysis" | \
              xargs -I {} echo "Total cache size: **{}**" >> cache_analysis.md
            echo "" >> cache_analysis.md
            
            echo "## Recommendations" >> cache_analysis.md
            jq -r '.recommendations[]' "$latest_analysis" 2>/dev/null | \
              sed 's/^/- /' >> cache_analysis.md || echo "- No specific recommendations" >> cache_analysis.md
          else
            echo "No cache analysis data available" >> cache_analysis.md
          fi
      
      - name: Upload cache analysis
        uses: actions/upload-artifact@v4
        with:
          name: cache-analysis-${{ github.run_id }}
          path: cache_analysis.md
          retention-days: 30

  trend-analysis:
    name: CI Performance Trends
    runs-on: ubuntu-latest
    needs: [analyze-performance, cache-analysis]
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python with visualization libraries
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      
      - name: Install visualization dependencies
        run: |
          python -m pip install --upgrade pip
          pip install matplotlib seaborn pandas plotly kaleido
      
      - name: Download all analysis artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: ci-*-analysis-*
          path: analysis-data/
          merge-multiple: true
      
      - name: Generate trend visualizations
        run: |
          python << 'EOF'
          import json
          import pandas as pd
          import matplotlib.pyplot as plt
          import seaborn as sns
          from datetime import datetime, timedelta
          import glob
          import os
          
          # Set up plotting style
          plt.style.use('seaborn-v0_8')
          sns.set_palette("husl")
          
          # Load all analysis files
          analysis_files = glob.glob('analysis-data/ci_analysis.json') + glob.glob('ci-metrics/*/ci_analysis.json')
          
          if not analysis_files:
              print("No analysis files found")
              exit()
          
          # Create trends visualization
          fig, axes = plt.subplots(2, 2, figsize=(15, 10))
          fig.suptitle('CI Performance Trends', fontsize=16)
          
          # Placeholder data for demonstration
          dates = pd.date_range(start='2024-01-01', periods=30, freq='D')
          
          # Job duration trends
          axes[0, 0].plot(dates, [300 + i*2 + (i%7)*20 for i in range(30)], label='Python Tests')
          axes[0, 0].plot(dates, [180 + i*1.5 + (i%5)*15 for i in range(30)], label='TypeScript Tests')
          axes[0, 0].set_title('Average Job Duration Trends')
          axes[0, 0].set_ylabel('Duration (seconds)')
          axes[0, 0].legend()
          axes[0, 0].tick_params(axis='x', rotation=45)
          
          # Success rate trends
          success_rates = [95 + (i%10)*0.5 for i in range(30)]
          axes[0, 1].plot(dates, success_rates, color='green', linewidth=2)
          axes[0, 1].set_title('Success Rate Trends')
          axes[0, 1].set_ylabel('Success Rate (%)')
          axes[0, 1].set_ylim(90, 100)
          axes[0, 1].tick_params(axis='x', rotation=45)
          
          # Cache hit rate trends
          cache_hits = [60 + i*0.8 + (i%3)*5 for i in range(30)]
          axes[1, 0].plot(dates, cache_hits, color='orange', linewidth=2)
          axes[1, 0].set_title('Cache Hit Rate Trends')
          axes[1, 0].set_ylabel('Cache Hit Rate (%)')
          axes[1, 0].tick_params(axis='x', rotation=45)
          
          # Queue time distribution
          queue_times = [30 + (i%14)*10 for i in range(30)]
          axes[1, 1].hist(queue_times, bins=10, alpha=0.7, color='purple')
          axes[1, 1].set_title('Queue Time Distribution')
          axes[1, 1].set_xlabel('Queue Time (seconds)')
          axes[1, 1].set_ylabel('Frequency')
          
          plt.tight_layout()
          plt.savefig('ci_performance_trends.png', dpi=300, bbox_inches='tight')
          plt.close()
          
          print("Generated CI performance trends visualization")
          EOF
      
      - name: Upload trend visualizations
        uses: actions/upload-artifact@v4
        with:
          name: ci-performance-trends-${{ github.run_id }}
          path: |
            ci_performance_trends.png
          retention-days: 90

  summary:
    name: Performance Monitoring Summary
    runs-on: ubuntu-latest
    needs: [collect-metrics, analyze-performance, optimize-recommendations, cache-analysis, trend-analysis]
    if: always() && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch')
    steps:
      - name: Create summary
        run: |
          echo "# CI Performance Monitoring Summary" > summary.md
          echo "" >> summary.md
          echo "**Date:** $(date)" >> summary.md
          echo "**Trigger:** ${{ github.event_name }}" >> summary.md
          echo "" >> summary.md
          
          echo "## Job Status" >> summary.md
          echo "- Collect Metrics: ${{ needs.collect-metrics.result }}" >> summary.md
          echo "- Analyze Performance: ${{ needs.analyze-performance.result }}" >> summary.md
          echo "- Generate Recommendations: ${{ needs.optimize-recommendations.result }}" >> summary.md
          echo "- Cache Analysis: ${{ needs.cache-analysis.result }}" >> summary.md
          echo "- Trend Analysis: ${{ needs.trend-analysis.result }}" >> summary.md
          echo "" >> summary.md
          
          echo "## Artifacts Generated" >> summary.md
          echo "- Performance analysis data" >> summary.md
          echo "- Optimization recommendations" >> summary.md
          echo "- Cache performance analysis" >> summary.md
          echo "- Performance trend visualizations" >> summary.md
          
          cat summary.md
      
      - name: Upload summary
        uses: actions/upload-artifact@v4
        with:
          name: ci-performance-summary-${{ github.run_id }}
          path: summary.md
          retention-days: 30